Objectives:
	- The need for Big-O-Notation 
	- Describe it
	- Simplify Big-O Expressions 
	- Define "time/space" complexity
	- Evaluate the time complexity and space complexity of different algorithms usings Big-O-Notation 
	- Describe what a logarithm is

# Write a function that accepts a string input and returns a reversed copy 

- is a way to formalize fuzzy counting 

- it allows us to talk formally about how the runtime of an algorithm grows as the inputs grow 

- ignore the other stuff <cs students make me sick some times> 

We say that an algorithm is O(f(n)) if the number of simple operations the computer has to do is eventually less than a constant times f(n), as n increases

- f(n) could be linear (f(n) = n) <- a function with the input of n has the output of n 
- f(n) could be quadratic (f(n) = n√)
- f(n) could be constant (f(n)) = 1) 
- f(n) could be something entirely different! 

# 3 operations (addition, multiplication and division) - this would have a big-o-notation of O(1) 
function addUpTO(n) { 
	return n * (n + 1) / 2; 
} 

# Number of operations is (eventually) bounded by a multiple of n (say, 10n) => O(n)  
function addUpTo(n) { 
  let total = 0; 
  for (let i = 1; i <= n; i++) {
    total += i;
  } 
  return total; 
}

- if there is a nested for loop inside of a for loop, you'll get O(n)O(n) which is => O(n√) 

O(1), O(n) O(n2) 

log(base2) of (8) = 3
